# 【论文阅读】Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable Features

ACL 2021

在具有可控特征的基于知识的对话中提高可信度

论文链接：https://aclanthology.org/2021.acl-long.58.pdf

## 1. 简介

 在这里，我们研究如何在对话中忠实于文本文档中的信息。我们通过基于知识的对话任务来解决这个问题，其中系统使用来自基础文档的证据和以前的对话历史作为输入来生成对话响应（如图1所示）。

![image-20210731222207237](https://gitee.com/cao-hu/pictures/raw/master/img/image-20210731222207237.png)

我们观察到基于知识的对话数据集通常包含具有不同对话风格和意图的话语，包括一些信息量更大的话语和一些闲聊话语或主观评论。

例如，在图 1 中，我们展示了来自维基百科向导训练集的示例对话摘录。 虽然一些话语得到了基础文件的支持（第二个回应），但其他话语包括个人经历和观察（如第一个回应）。

由于这种对话风格的混合，我们无法确保在这些数据上直接进行训练的模型将学会仅生成可靠的、信息丰富的话语

**我们采用可控文本生成技术来训练对话模型，学习在数据中分开这些对话风格，并且可以在生成时进行控制以产生更充实的回复。**

我们提出使用与回复真实性相关的多种评估指标，并使用这些指标控制两种常用seq2seq模型（GPT-2和T5）的输出。我们研究了两种增加可控性的方法。

1. 首先，我们将基于评估指标的control code features集成为seq2seq输入的特殊标记。
2. 其次，我们实现了一种直接限制输出的重采样形式，以满足提出的评估指标。

## 2.方法

### 2.1 任务

我们引入了一个基于知识的对话的子任务，**其中对话代理旨在提供信息并且不得share幻觉**，我们在此将幻觉定义为既不能从外部文件中推断出也不能由外部文件直接陈述的任何信息。 在此任务中，系统从一个或多个文档和对话历史中获得证据，并且必须产生既忠实于证据又在先前对话话语的上下文中自然的响应。 由于此任务侧重于向用户提供信息，因此不允许代理共享不受支持的或主观的信息（这包括虚构的个人特征 - 例如“我也喜欢狗！”）。 此外，仅仅提取是不够的，因为证据中的信息可能需要重新表述为适合对话的响应（例如，如果用户提出的问题可从证据中推断出但未直接陈述）。

为了简化本文的任务，我们假设已经标记了适当的证据范围 e。 因此，我们研究如何在给定先前对话历史 x 和选择的证据 e 作为输入的情况下生成适当的响应 y。

### 2.2 评估指标

我们的目标是设计一个在如何传递证据方面更加忠实和客观的对话模型。 我们提出使用一系列评估指标来估计回复是否是 (1) 客观的，(2) 不共享文档中没有的额外信息， (3) 由基础证据引起的。 

+ **Objective Voice**
+ **Lexical Precision**
+ **Entailment**

### 2.3 模型

#### 2.3.1 生成模型

​	T5和GPT-2

#### 2.3.2 添加可控生成

##### 2.3.2.1 Control Code Features

我们添加控制特征来鼓励底层语言模型在训练时分离不同对话风格。 

首先，我们使用前面介绍的指标，根据回复的多少内容基于gold标记的证据来创建控制特征token。 控制特征标记 c1...cn 被附加到其他标记之前。

$\mathcal{L}_{C E}=-\frac{1}{n} \sum_{i=1}^{n} \log p\left(y_{i} \mid y_{<i}, x, e, c\right)$

在训练时，我们根据gold response的entailment,lexical precision,objective voice来设置控制特征标记。 在解码时，控制代码被设置为这些指标所需的值。

+ **Objective Voice**:话语是否包含第一人称代词，<first-person>,<no-first-person>，解码时，统一使用<no-first-person>控制标记。
+ **Lexical Precision**：我们根据回复和evidence的词汇精度，将训练话语分为（<high-prec>,<med-prec>,<low-prec>）。解码时，总是使用<high-prec>。
+ **Entailment**：我们用NLI 分类器的输出添加控制码（<entailed>,<non-entailed>）。解码时，总是使用<entailed>。

****

##### 2.3.2.2 Controlled resampling

尽管控制码方法隐式地教导模型使用不同的样式，但某些应用程序可能需要对模型输出进行更直接的控制。 此外，可能存在无法重新训练对话系统的情况。 因此，我们还研究了一种在解码时实现更直接控制的方法。 我们试验了一种重采样方法，该方法继续对响应进行采样，直到发现满足评估措施。 为了节省计算效率，我们使用cut-off来避免重采样超过 d 次。

![image-20210731230811888](https://gitee.com/cao-hu/pictures/raw/master/img/image-20210731230811888.png)